{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYfa-1Cl9WFd",
        "outputId": "8ffcc2d0-8ea7-4cf6-c88a-b2dbe1140699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHaUnB2-wML",
        "outputId": "24545f92-a587-4700-b9ca-7223b33de2dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "import logging\n",
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "BreIwG8I_eRl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[\n",
        "    logging.StreamHandler()\n",
        "])"
      ],
      "metadata": {
        "id": "ZAWfPd-BFVQY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_time(start_time: float, end_time: float) -> float:\n",
        "    \"\"\"\n",
        "    Calculate opearation execution time in milliseconds.\n",
        "\n",
        "    Args:\n",
        "        start_time (float): Start time in seconds.\n",
        "        end_time (float): End time in seconds.\n",
        "\n",
        "    Returns:\n",
        "        float: Elapsed time in milliseconds.\n",
        "    \"\"\"\n",
        "    return (end_time - start_time) * 1000"
      ],
      "metadata": {
        "id": "36dUUJ_RA9tJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageProcessor(Dataset):\n",
        "    \"\"\"\n",
        "    A custom dataset class for loading images and preprocessing them to the appropriate format.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_folder):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_files = [\n",
        "            f for f in os.listdir(image_folder)\n",
        "            if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Modified version of the __getitem__ function that support profiling.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the image.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image_tensor, image_name, load_time, preprocess_time, total_time)\n",
        "                image_tensor (torch.Tensor): The preprocessed image tensor.\n",
        "                image_name (str): The name of the image file.\n",
        "                load_time (float): Time taken to load the image (milliseconds).\n",
        "                preprocess_time (float): Time taken to preprocess the image (milliseconds).\n",
        "                total_time (float): Total time for loading and preprocessing (milliseconds).\n",
        "        \"\"\"\n",
        "\n",
        "        load_start_time = time.time()\n",
        "\n",
        "        image_name = self.image_files[idx]\n",
        "        image_path = os.path.join(self.image_folder, image_name)\n",
        "\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        load_end_time = time.time()\n",
        "        load_time = count_time(load_start_time, load_end_time)\n",
        "\n",
        "        preprocess_start_time = time.time()\n",
        "\n",
        "        preprocess_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        image_tensor = preprocess_transform(image)\n",
        "\n",
        "        preprocess_end_time = time.time()\n",
        "        preprocess_time = count_time(preprocess_start_time, preprocess_end_time)\n",
        "\n",
        "        total_time = count_time(load_start_time, preprocess_end_time)\n",
        "\n",
        "        return image_tensor, image_name, load_time, preprocess_time, total_time"
      ],
      "metadata": {
        "id": "ePPslLMYBMqk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModelProfiler(ABC):\n",
        "    \"\"\"\n",
        "    Abstract base class for model profilers.\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    @abstractmethod\n",
        "    def profile(self, inputs):\n",
        "        \"\"\"\n",
        "        Abstract method for model profiling injection\n",
        "\n",
        "        Args:\n",
        "            inputs: The inputs to the model.\n",
        "\n",
        "        Returns:\n",
        "            outputs: The outputs from the model.\n",
        "            layer_times: Dictionary mapping layer names to execution times (milliseconds).\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "X11bjxY4J8iD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelProfiler(BaseModelProfiler):\n",
        "    \"\"\"\n",
        "    Generic Model Profiler, can be used for any sequence to sequence model.\n",
        "    \"\"\"\n",
        "    def profile(self, inputs):\n",
        "        \"\"\"\n",
        "        Profile the model by iterating over its layers.\n",
        "\n",
        "        Args:\n",
        "            inputs: The inputs to the model.\n",
        "\n",
        "        Returns:\n",
        "            outputs: The outputs from the model.\n",
        "            layer_times: Dictionary mapping layer names to execution times (milliseconds).\n",
        "        \"\"\"\n",
        "        layer_times = {}\n",
        "        x = inputs\n",
        "        for name, layer in self.model.named_children():\n",
        "            start_time = time.time()\n",
        "            x = layer(x)\n",
        "            end_time = time.time()\n",
        "            layer_times[name] = count_time(start_time, end_time)\n",
        "        return x, layer_times"
      ],
      "metadata": {
        "id": "ESipgBOOBNdu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the model was selected **FasterRCNN**, because of the next reasons:\n",
        "\n",
        "\n",
        "1.   Not a fully sequential model.\n",
        "2.   Built-in pytorch support, no additional modules needed.\n",
        "3.   More complex than YOLO.\n",
        "\n",
        "Because creation of completely generic profiler that can be used for any model, without hooks is not available, I decided to go with approach of Abstract classes. Most of the code can be reused by simple inheritance from ModelProfiler or From BaseModelProfiler.\n",
        "\n"
      ],
      "metadata": {
        "id": "TzJKXCBeWGpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FasterRCNNProfiler(BaseModelProfiler):\n",
        "    \"\"\"\n",
        "    A model profiler class specially designed for FasterRCNN based on BaseModelProfiler.\n",
        "    \"\"\"\n",
        "    def profile(self, images):\n",
        "        \"\"\"\n",
        "        Perform a forward pass through the model, profiling each major layer\n",
        "\n",
        "        Args:\n",
        "            images (list[Tensor]): List of images to be processed.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (detections, component_times)\n",
        "                detections (list[dict]): Detection results from the model.\n",
        "                component_times (dict): Dictionary mapping component names to execution times (milliseconds).\n",
        "        \"\"\"\n",
        "        component_times = {}\n",
        "\n",
        "        start_time = time.time()\n",
        "        images, targets = self.model.transform(images)\n",
        "        end_time = time.time()\n",
        "        component_times['transform'] = count_time(start_time, end_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        features = self.model.backbone(images.tensors)\n",
        "        end_time = time.time()\n",
        "        component_times['backbone'] = count_time(start_time, end_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        proposals, proposal_losses = self.model.rpn(images, features, targets)\n",
        "        end_time = time.time()\n",
        "        component_times['rpn'] = count_time(start_time, end_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        detections, detector_losses = self.model.roi_heads(features, proposals, images.image_sizes, targets)\n",
        "        end_time = time.time()\n",
        "        component_times['roi_heads'] = count_time(start_time, end_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        detections = self.model.transform.postprocess(detections, images.image_sizes, images.image_sizes)\n",
        "        end_time = time.time()\n",
        "        component_times['postprocess'] = count_time(start_time, end_time)\n",
        "\n",
        "        return detections, component_times"
      ],
      "metadata": {
        "id": "z8WWif20KAEG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocessing(image_name, image_tensor, detections, save_folder):\n",
        "    \"\"\"\n",
        "    Postprocess function that draw bounding boxes and save them to a folder on Google Drive.\n",
        "\n",
        "    Args:\n",
        "        image_name (str): Name of the image file.\n",
        "        image_tensor (torch.Tensor): The preprocessed image tensor.\n",
        "        detections (dict): Model detections containing 'boxes' and 'scores'.\n",
        "        save_folder (str): Folder to save the processed images.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (post_time, processed_image)\n",
        "            post_time (float): Time taken for postprocessing (milliseconds).\n",
        "            processed_image (PIL.Image.Image): The image with bounding boxes drawn.\n",
        "    \"\"\"\n",
        "    post_start_time = time.time()\n",
        "\n",
        "    image = transforms.ToPILImage()(image_tensor.cpu())\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    boxes = detections['boxes']\n",
        "    scores = detections['scores']\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        if scores[i] > 0.5:\n",
        "            box = boxes[i]\n",
        "            draw.rectangle(box.tolist(), outline='red', width=2)\n",
        "\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    save_path = os.path.join(save_folder, image_name)\n",
        "    image.save(save_path)\n",
        "\n",
        "    post_end_time = time.time()\n",
        "    post_time = count_time(post_start_time, post_end_time)\n",
        "\n",
        "    return post_time, image"
      ],
      "metadata": {
        "id": "MCYdfr2XBNl5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(image_folder, save_folder, log_file_path, batch_size=1, device='cpu'):\n",
        "    \"\"\"\n",
        "    Run the entire pipeline that includes: loading, preprocessing, inference, postprocessing, and logging.\n",
        "\n",
        "    Args:\n",
        "        image_folder (str): Path to the folder containing input images.\n",
        "        save_folder (str): Path to the folder to save processed images.\n",
        "        log_file_path (str): Path to the log file to save profiling logs.\n",
        "        batch_size (int, optional): Batch size for processing. Defaults to 1.\n",
        "        device (str, optional): Device to run the pipeline on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
        "    \"\"\"\n",
        "    dataset = ImageProcessor(image_folder)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    profiled_model = FasterRCNNProfiler(model)\n",
        "\n",
        "    logger = logging.getLogger('PipelineLogger')\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    fh = logging.FileHandler(log_file_path)\n",
        "    fh.setLevel(logging.INFO)\n",
        "\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "\n",
        "    if not logger.handlers:\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    for data in dataloader:\n",
        "        images, image_names, load_times, preprocess_times, total_times = data\n",
        "\n",
        "        images = images.to(device)\n",
        "\n",
        "        images_list = [images[i] for i in range(images.shape[0])]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            infer_start_time = time.time()\n",
        "            detections_list, component_times = profiled_model.profile(images_list)\n",
        "            infer_end_time = time.time()\n",
        "            inference_time = count_time(infer_start_time, infer_end_time)\n",
        "\n",
        "        for idx in range(len(images)):\n",
        "            image_tensor = images[idx]\n",
        "            image_name = image_names[idx]\n",
        "            detections = detections_list[idx]\n",
        "\n",
        "            post_time, processed_image = postprocessing(image_name, image_tensor, detections, save_folder)\n",
        "\n",
        "            logger.info(f\"Device: {device.upper()}\")\n",
        "            logger.info(f\"Image: {image_name}\")\n",
        "            logger.info(f\"Loading time: {load_times[idx].item():.2f} ms\")\n",
        "            logger.info(f\"Preprocessing time: {preprocess_times[idx].item():.2f} ms\")\n",
        "            logger.info(f\"Inference time: {inference_time:.2f} ms\")\n",
        "            logger.info(f\"Postprocessing time: {post_time:.2f} ms\")\n",
        "            logger.info(\"Component times:\")\n",
        "            for component_name, c_time in component_times.items():\n",
        "                logger.info(f\"  {component_name}: {c_time:.2f} ms\")\n",
        "            logger.info(\"-\" * 30)\n",
        "\n",
        "    logger.removeHandler(fh)\n",
        "    fh.close()"
      ],
      "metadata": {
        "id": "JvyxUlyKEi8r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    image_folder = '/content/drive/My Drive/neureality_test_task'\n",
        "    save_folder_gpu = '/content/drive/My Drive/output_images_gpu'\n",
        "    save_folder_cpu = '/content/drive/My Drive/output_images_cpu'\n",
        "\n",
        "    log_file_gpu = '/content/drive/My Drive/performance_log_gpu.txt'\n",
        "    log_file_cpu = '/content/drive/My Drive/performance_log_cpu.txt'\n",
        "\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "\n",
        "    if cuda_available:\n",
        "        logging.info(\"Running on GPU...\")\n",
        "        run_pipeline(image_folder, save_folder_gpu, log_file_gpu, batch_size=1, device='cuda')\n",
        "    else:\n",
        "        logging.info(\"CUDA is not available. Skipping GPU run.\")\n",
        "\n",
        "    logging.info(\"Running on CPU...\")\n",
        "    run_pipeline(image_folder, save_folder_cpu, log_file_cpu, batch_size=1, device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHQFhOI0FGMv",
        "outputId": "bcd32f9f-0226-4441-c695-24c487b9e449"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:02<00:00, 63.0MB/s]\n",
            "INFO:PipelineLogger:Device: CUDA\n",
            "INFO:PipelineLogger:Image: gettyimages-76208034-612x612.jpg\n",
            "INFO:PipelineLogger:Loading time: 581.72 ms\n",
            "INFO:PipelineLogger:Preprocessing time: 4.36 ms\n",
            "INFO:PipelineLogger:Inference time: 1911.06 ms\n",
            "INFO:PipelineLogger:Postprocessing time: 309.64 ms\n",
            "INFO:PipelineLogger:Component times:\n",
            "INFO:PipelineLogger:  transform: 98.42 ms\n",
            "INFO:PipelineLogger:  backbone: 722.84 ms\n",
            "INFO:PipelineLogger:  rpn: 905.90 ms\n",
            "INFO:PipelineLogger:  roi_heads: 183.54 ms\n",
            "INFO:PipelineLogger:  postprocess: 0.31 ms\n",
            "INFO:PipelineLogger:------------------------------\n",
            "INFO:PipelineLogger:Device: CUDA\n",
            "INFO:PipelineLogger:Image: gettyimages-1392016982-612x612.jpg\n",
            "INFO:PipelineLogger:Loading time: 417.81 ms\n",
            "INFO:PipelineLogger:Preprocessing time: 2.63 ms\n",
            "INFO:PipelineLogger:Inference time: 121.41 ms\n",
            "INFO:PipelineLogger:Postprocessing time: 314.72 ms\n",
            "INFO:PipelineLogger:Component times:\n",
            "INFO:PipelineLogger:  transform: 0.46 ms\n",
            "INFO:PipelineLogger:  backbone: 10.85 ms\n",
            "INFO:PipelineLogger:  rpn: 91.02 ms\n",
            "INFO:PipelineLogger:  roi_heads: 18.82 ms\n",
            "INFO:PipelineLogger:  postprocess: 0.23 ms\n",
            "INFO:PipelineLogger:------------------------------\n",
            "INFO:PipelineLogger:Device: CPU\n",
            "INFO:PipelineLogger:Image: gettyimages-76208034-612x612.jpg\n",
            "INFO:PipelineLogger:Loading time: 5.85 ms\n",
            "INFO:PipelineLogger:Preprocessing time: 2.75 ms\n",
            "INFO:PipelineLogger:Inference time: 5235.87 ms\n",
            "INFO:PipelineLogger:Postprocessing time: 422.56 ms\n",
            "INFO:PipelineLogger:Component times:\n",
            "INFO:PipelineLogger:  transform: 31.86 ms\n",
            "INFO:PipelineLogger:  backbone: 2829.75 ms\n",
            "INFO:PipelineLogger:  rpn: 1603.68 ms\n",
            "INFO:PipelineLogger:  roi_heads: 768.02 ms\n",
            "INFO:PipelineLogger:  postprocess: 0.13 ms\n",
            "INFO:PipelineLogger:------------------------------\n",
            "INFO:PipelineLogger:Device: CPU\n",
            "INFO:PipelineLogger:Image: gettyimages-1392016982-612x612.jpg\n",
            "INFO:PipelineLogger:Loading time: 4.98 ms\n",
            "INFO:PipelineLogger:Preprocessing time: 3.73 ms\n",
            "INFO:PipelineLogger:Inference time: 6604.20 ms\n",
            "INFO:PipelineLogger:Postprocessing time: 276.85 ms\n",
            "INFO:PipelineLogger:Component times:\n",
            "INFO:PipelineLogger:  transform: 26.51 ms\n",
            "INFO:PipelineLogger:  backbone: 4288.90 ms\n",
            "INFO:PipelineLogger:  rpn: 1396.01 ms\n",
            "INFO:PipelineLogger:  roi_heads: 885.36 ms\n",
            "INFO:PipelineLogger:  postprocess: 0.13 ms\n",
            "INFO:PipelineLogger:------------------------------\n"
          ]
        }
      ]
    }
  ]
}